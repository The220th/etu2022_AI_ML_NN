{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "\n",
    "import zipfile\n",
    "\n",
    "\n",
    "__z = zipfile.ZipFile(\"dataset.zip\")\n",
    "#df_str = __z.open(\"Vehicle_policies_2020.csv\").read().decode(\"utf-8\")\n",
    "df_str_fs = __z.open(\"Vehicle_policies_2020.csv\")\n",
    "\n",
    "df_src = pd.read_csv(df_str_fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b8e0e",
   "metadata": {},
   "source": [
    "# Предварительная обработка данных\n",
    "\n",
    "Данные [отсюда](https://www.kaggle.com/datasets/lakshmanraj/vehicle-insurance-policy):\n",
    "\n",
    "~~1. pol_number - Номер полюса~~\n",
    "\n",
    "~~2. pol_eff_dt - Дата вступления в силу полиса автострахования~~\n",
    "\n",
    "3. gender - Пол водителя: F, M\n",
    "\n",
    "4. agecat - Возрастная категория водителя: 1, 2, 3, 4, 5, 6 (1 - моложе, ..., 6 - старше)\n",
    "\n",
    "~~5. date_of_birth - Дата рождения водителя~~\n",
    "\n",
    "6. credit_score - Кредитный рейтинг водителя: от 301=плохо до 850=прекрасно\n",
    "\n",
    "7. area - Категория: A, B, C, D, E, F\n",
    "\n",
    "8. traffic_index - Дорожный индекс района проживания водителя:\n",
    "\n",
    "- 100 = среднее по стране\n",
    "\n",
    "- Больше 100 = плохие условия движения\n",
    "\n",
    "- Меньше 100 = хорошие условия движения\n",
    "\n",
    "9. veh_age - Возраст транспортного средства: 1, 2, 3, 4 (1 - новее, ..., 4 - старее)\n",
    "\n",
    "10. veh_body - Кузов транспортного средства, coded as:\n",
    "- BUS\n",
    "- CONVT = convertible\n",
    "- COUPE\n",
    "- HBACK = hatchback\n",
    "- HDTOP = hardtop\n",
    "- MCARA = motorized caravan\n",
    "- MIBUS = minibus\n",
    "- PANVN = panel van\n",
    "- RDSTR = roadster\n",
    "- STNWG = station wagon\n",
    "- TRUCK\n",
    "- UTE = utility\n",
    "\n",
    "11. veh_value - Стоимость транспортного средства, в $10 000\n",
    "\n",
    "~~12. months_insured - Количество месяцев, на которые приобретена страховка транспортного средства~~\n",
    "\n",
    "~~13. claim_office - Office location of claim handling agent: A, B, C, D~~\n",
    "\n",
    "14. numclaims - Кол-во претензий: 0=нет_претензий\n",
    "\n",
    "15. claimcst0 - Стоимость претензий: 0=нет_претензий\n",
    "\n",
    "~~16. annual_premium - Total charged premium i.e. the cost of insurance~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146a53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look dataframe\n",
    "pd.set_option('display.max_columns', df_src.shape[1])\n",
    "df_src.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad34610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look dataframe\n",
    "#df_src.head()\n",
    "pd.set_option('display.max_columns', df_src.shape[1])\n",
    "df_src.tail(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f4401",
   "metadata": {},
   "source": [
    "# Проектирование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b082bf",
   "metadata": {},
   "source": [
    "## Убираем дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8501106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Number of (rows, columns): {df_src.shape}\")\n",
    "duplicate_rows_df = df_src[df_src.duplicated()]\n",
    "print(f\"Number of duplicate (rows, columns): {duplicate_rows_df.shape}\")\n",
    "df_src = df_src.drop_duplicates()\n",
    "print(f\"Number of (rows, columns) after drop dublicates: {df_src.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b065abc",
   "metadata": {},
   "source": [
    "## Смотрим, чтобы не было нерелевантных данных\n",
    "\n",
    "### Как поступить с такими данными?\n",
    "\n",
    "![](./imgs/if_missing_data.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed45b78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df_src.shape[1])\n",
    "df_src.count() # Кол-во не None значений в каждой колонке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe95a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df_src.shape[1])\n",
    "print(df_src.isnull().sum()) # Смотрим есть ли null хотя бы в каком-нибудь столбце\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8512c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Удалим посностью claim_office\n",
    "del df_src[\"claim_office\"]\n",
    "\n",
    "# Удалим date_of_birth\n",
    "del df_src[\"date_of_birth\"]\n",
    "\n",
    "# Удалим pol_number\n",
    "del df_src[\"pol_number\"]\n",
    "\n",
    "# Удалим null'ы\n",
    "df_src = df_src.dropna()\n",
    "\n",
    "# Удалим дубликаты, если они появились после удаления столбцов\n",
    "df_src = df_src.drop_duplicates()\n",
    "\n",
    "print(f\"\\nNumber of (rows, columns): {df_src.shape}\")\n",
    "\n",
    "print(\"\\nКол-во не None значений:\")\n",
    "print(df_src.count())\n",
    "\n",
    "print(\"\\nКол-во null\\'ов:\")\n",
    "print(df_src.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f47927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,50))\n",
    "\n",
    "df_src.hist(column=\"annual_premium\")\n",
    "\n",
    "print(f\"Range of annual_premium: [{df_src['annual_premium'].min()} - {df_src['annual_premium'].max()}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037989f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date_check = df_src.copy()\n",
    "\n",
    "basedate = pd.Timestamp(\"2022-11-28\")\n",
    "# basedate = pd.Timestamp(\"11/28/2022\") # То что в столбце \"pol_eff_dt\", тип str\n",
    "            # pd.Timestamp(\"2022-11-28\") and pd.Timestamp(\"11/28/2022\") are equals\n",
    "\n",
    "df_date_check[\"time_since_in_days\"] = df_date_check[\"pol_eff_dt\"].apply(lambda x: (basedate - pd.Timestamp(x)).days)\n",
    "\n",
    "\n",
    "#df_date_check.hist(column=\"time_since_in_days\")\n",
    "print(f\"Range of pol_eff_dt: [{df_date_check['time_since_in_days'].min()} - {df_date_check['time_since_in_days'].max()}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Никчёмные столбецы\n",
    "del df_src[\"annual_premium\"]\n",
    "del df_src[\"pol_eff_dt\"]\n",
    "           \n",
    "df_src = df_src.drop_duplicates()\n",
    "           \n",
    "print(f\"\\nNumber of (rows, columns): {df_src.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5463cae",
   "metadata": {},
   "source": [
    "### В итоге будут убраны столбцы:\n",
    "\n",
    "- `claim_office`: По большей части - это `null`'ы. \n",
    "\n",
    "- `date_of_birth`: Зачем это нужно, если есть `agecat`. \n",
    "\n",
    "- `pol_number`: Номер полюса никак не влияет. \n",
    "\n",
    "- `annual_premium`: Одно и тоже число. \n",
    "\n",
    "- `pol_eff_dt`: Дата оформления полюса не влияет на кластеризацию. Плюс ко всем, здесь период всего лишь 363 дня. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a022623b",
   "metadata": {},
   "source": [
    "## Кодирование строк + float->int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e3de3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Смотрим типы столбцов\n",
    "\n",
    "pd.set_option('display.max_rows', df_src.shape[1])\n",
    "\n",
    "nullout = '''\n",
    "Должно быть:\n",
    "\n",
    "pol_number          int64\n",
    "pol_eff_dt         cat->int\n",
    "gender             cat->int\n",
    "agecat              int64\n",
    "credit_score        int64\n",
    "area               cat->int\n",
    "traffic_index       int64\n",
    "veh_age             int64\n",
    "veh_body           cat->int\n",
    "veh_value         float64\n",
    "numclaims           int64\n",
    "claimcst0         float64\n",
    "'''\n",
    "\n",
    "df_src.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nums = df_src.copy()\n",
    "\n",
    "# Инты там, где они нужны\n",
    "ints_cols = [\"agecat\", \"credit_score\", \"traffic_index\"]\n",
    "df_nums[ ints_cols ] = df_nums[ints_cols].astype(int)\n",
    "\n",
    "# Категориальные:\n",
    "\n",
    "# veh_body\n",
    "df_nums[\"veh_body\"] = df_nums[\"veh_body\"].astype('category')\n",
    "df_nums[\"veh_body\"] = df_nums[\"veh_body\"].cat.codes\n",
    "df_nums[\"veh_body\"] = df_nums[\"veh_body\"].astype(int)\n",
    "\n",
    "# Не veh_body\n",
    "cat_code = {\"gender\": {\"M\": 0, \"F\": 1}, \n",
    "            \"area\": {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3, \"E\": 4, \"F\": 5}}\n",
    "df_nums = df_nums.replace(cat_code)\n",
    "\n",
    "pd.set_option('display.max_rows', df_src.shape[1])\n",
    "df_nums.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f98c9d",
   "metadata": {},
   "source": [
    "## Нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nums_scaled = df_nums.copy()\n",
    "df_nums_scaled = (df_nums-df_nums.min ())/(df_nums.max ()-df_nums.min ())\n",
    "df_nums_scaled.head(300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c3d68",
   "metadata": {},
   "source": [
    "# Графики\n",
    "\n",
    "![](./imgs/which_visualization.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26067da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns_of_interest = [\"credit_score\", \"traffic_index\", \"veh_value\", \"numclaims\", \"claimcst0\"]\n",
    "for col_i in numeric_columns_of_interest:\n",
    "    print(f\"Range of {col_i}: [{df_src[col_i].min()} - {df_src[col_i].max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fae59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Тепловая карта\n",
    "\n",
    "plt.figure(figsize=(25, 13))\n",
    "c= df_nums.corr()\n",
    "sns.heatmap(c, cmap=\"BrBG\", annot=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12149c2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Гистограммы\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "cols = df_nums.columns\n",
    "for col_i in cols:\n",
    "    df_nums.hist(column=col_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00cda0",
   "metadata": {},
   "source": [
    "# Кластеризация\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.mixture import GaussianMixture as EM\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "RndState = 5051\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50551ee0",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = [] # inertia\n",
    "N_max = 13\n",
    "\n",
    "for i in range(1, N_max):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=RndState).fit(df_nums)\n",
    "    Js.append(np.sqrt(kmeans.inertia_))\n",
    "\n",
    "Ds = []\n",
    "for i in range(1, len(Js)-1):\n",
    "    Ds.append( abs(Js[i] - Js[i+1]) / abs(Js[i-1] - Js[i]) )\n",
    "Ds = [round(Ds[i], 3) for i in range(len(Ds))]\n",
    "print(f\"Ds = {Ds}, \\nmin = {min(Ds)} with k = {Ds.index(min(Ds))+1}\")\n",
    "    \n",
    "plt.plot(range(1, N_max), Js, marker=\"s\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"$J(C_k)$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b3f56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Число кластеров 9 звучит хорошо\n",
    "N_CLASTERS = 9\n",
    "kmeans = KMeans(n_clusters=N_CLASTERS, random_state=RndState).fit(df_nums)\n",
    "\n",
    "#print(f\"kmeans.labels={len(kmeans.labels_)}, number of rows = {df_nums.shape[0]}\")\n",
    "\n",
    "d_classes = {i: 0 for i in range(N_CLASTERS)}\n",
    "for i in kmeans.labels_:\n",
    "    d_classes[i] += 1\n",
    "\n",
    "print(f\"Numbers of classes: {d_classes}\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "res = pca.fit_transform(df_nums)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(res[:,0], res[:,1], c=kmeans.labels_, s=50, cmap='viridis')\n",
    "plt.title('PCA')\n",
    "\n",
    "print(f\"\\n=====\\nSilhouette says: {metrics.silhouette_score(df_nums, kmeans.labels_)}\\n=====\") \n",
    "# From {-1} is super bad   --->   to {1} is super good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650b7e3",
   "metadata": {},
   "source": [
    "## Mean-Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6049cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_nums_scaled.copy()\n",
    "\n",
    "for bandwidth_i_int in range(5, 100, 10):\n",
    "    bandwidth_i = bandwidth_i_int / 100\n",
    "    flat_shift = MeanShift(bandwidth=bandwidth_i).fit(df)\n",
    "    number_of_class = len(set(flat_shift.labels_))\n",
    "    print(f\"\\nFor bandwidth={bandwidth_i} {number_of_class} classes\")\n",
    "    if(number_of_class < 15):\n",
    "        d = defaultdict(lambda:0)\n",
    "        for row_i in flat_shift.labels_:\n",
    "            d[row_i] += 1\n",
    "        print(f\"\\t{d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пусть bandwidth=\n",
    "flat_shift = MeanShift(bandwidth=0.5).fit(df_nums_scaled)\n",
    "d = defaultdict(lambda:0)\n",
    "for row_i in flat_shift.labels_:\n",
    "    d[row_i] += 1\n",
    "\n",
    "print(f\"Numbers of classes: {d}\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "res = pca.fit_transform(df_nums_scaled)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(res[:,0], res[:,1], c=flat_shift.labels_, s=50, cmap='viridis')\n",
    "plt.title('PCA')\n",
    "\n",
    "print(f\"\\n=====\\nSilhouette says: {metrics.silhouette_score(df_nums_scaled, flat_shift.labels_)}\\n=====\")\n",
    "# From {-1} is super bad   --->   to {1} is super good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e26be",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98238df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df_nums_scaled.copy()\n",
    "\n",
    "for eps_i_int in range(5, 50, 5):\n",
    "    eps_i = eps_i_int / 100\n",
    "    for min_samples_i in range(3, 9, 2):\n",
    "        dbscan = DBSCAN(eps=eps_i, min_samples=min_samples_i).fit(df)\n",
    "        number_of_class = len(set(dbscan.labels_))\n",
    "        print(f\"\\nFor eps={eps_i} and min_samples={min_samples_i} {number_of_class} classes\")\n",
    "        if(number_of_class < 15):\n",
    "            d = defaultdict(lambda:0)\n",
    "            for row_i in dbscan.labels_:\n",
    "                d[row_i] += 1\n",
    "            print(f\"\\t{d}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a54530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пусть eps=0.3 and min_samples=7\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=7).fit(df_nums_scaled)\n",
    "d = defaultdict(lambda:0)\n",
    "for row_i in dbscan.labels_:\n",
    "    d[row_i] += 1\n",
    "\n",
    "print(f\"Numbers of classes: {d}\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "res = pca.fit_transform(df_nums_scaled)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(res[:,0], res[:,1], c=dbscan.labels_, s=50, cmap='viridis')\n",
    "plt.title('PCA')\n",
    "\n",
    "print(f\"\\n=====\\nSilhouette says: {metrics.silhouette_score(df_nums_scaled, dbscan.labels_)}\\n=====\")\n",
    "# From {-1} is super bad   --->   to {1} is super good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509990e",
   "metadata": {},
   "source": [
    "## Иерархическая кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Js = [] # inertia\n",
    "N_max = 13\n",
    "\n",
    "for i in range(1, N_max):\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=i).fit(df_nums)\n",
    "    Js.append(np.sqrt(agglomerative.inertia_))\n",
    "\n",
    "Ds = []\n",
    "for i in range(1, len(Js)-1):\n",
    "    Ds.append( abs(Js[i] - Js[i+1]) / abs(Js[i-1] - Js[i]) )\n",
    "Ds = [round(Ds[i], 3) for i in range(len(Ds))]\n",
    "print(f\"Ds = {Ds}, \\nmin = {min(Ds)} with k = {Ds.index(min(Ds))+1}\")\n",
    "    \n",
    "plt.plot(range(1, N_max), Js, marker=\"s\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"$J(C_k)$\")\n",
    "\n",
    "\n",
    "# Комп умер, GG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afa926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# верхний треугольник матрицы попарных расстояний\n",
    "distance_mat = pdist(df_nums)\n",
    "    \n",
    "\n",
    "Z = hierarchy.linkage(distance_mat, \"complete\")\n",
    "            # linkage — реализация агломеративного алгоритма\n",
    "    \n",
    "plt.figure(figsize=(10, 5))\n",
    "dn = hierarchy.dendrogram(Z, color_threshold=0.5)\n",
    "\n",
    "# Комп умер, GG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efcb62e",
   "metadata": {},
   "source": [
    "## EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08574bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_max = 13\n",
    "\n",
    "for i in range(1, N_max):\n",
    "    em = GaussianMixture(n_components=i, random_state=RndState).fit(df_nums_scaled)\n",
    "    pd.set_option('display.max_rows', i)\n",
    "    print(f\"\\n{pd.DataFrame(em.predict(df_nums_scaled)).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffce4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пусть n_components=9\n",
    "N_CLASTERS = 9\n",
    "em = GaussianMixture(n_components=N_CLASTERS, random_state=RndState).fit(df_nums_scaled)\n",
    "\n",
    "em_labels = em.predict(df_nums_scaled)\n",
    "d_classes = {i: 0 for i in range(N_CLASTERS)}\n",
    "for i in em_labels:\n",
    "    d_classes[i] += 1\n",
    "\n",
    "print(f\"Numbers of classes: {d_classes}\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "res = pca.fit_transform(df_nums)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(res[:,0], res[:,1], c=em.predict(df_nums_scaled), s=50, cmap='viridis')\n",
    "plt.title('PCA')\n",
    "\n",
    "print(f\"\\n=====\\nSilhouette says: {metrics.silhouette_score(df_nums_scaled, em_labels)}\\n=====\")\n",
    "# From {-1} is super bad   --->   to {1} is super good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
